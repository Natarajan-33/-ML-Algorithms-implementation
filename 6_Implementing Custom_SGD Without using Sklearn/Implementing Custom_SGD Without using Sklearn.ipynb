{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "- Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn's SGD function and at the end compare our implementation with the sklearn's implementation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "\n",
    "# you need not standardize the data as it is already standardized\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;constant&#x27;, loss=&#x27;log&#x27;,\n",
       "              random_state=15, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;constant&#x27;, loss=&#x27;log&#x27;,\n",
       "              random_state=15, verbose=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 10 epochs took 0.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natar\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;constant&#x27;, loss=&#x27;log&#x27;,\n",
       "              random_state=15, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(eta0=0.0001, learning_rate=&#x27;constant&#x27;, loss=&#x27;log&#x27;,\n",
       "              random_state=15, verbose=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom implementation of SGD classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(row_vector):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    # zeros_like function to initialize zero: https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    w=np.zeros_like(row_vector)\n",
    "    b=0      #initializing bias to zero\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "id": "A7I6uWBRsKc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(X_train[0])\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    if z >= 0:                          #to avoid overflow problem : referene taken from: https://developer.ibm.com/articles/implementing-logistic-regression-from-scratch-in-python/\n",
    "        z = np.exp(-z)            \n",
    "        return 1 / (1 + z)\n",
    "    else:\n",
    "        z = np.exp(z)\n",
    "        return z / (1 + z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    #while dealing with numpy arrays you can use vectorized operations for quicker calculations as compared to using loops\n",
    "    #https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html\n",
    "    #https://www.geeksforgeeks.org/vectorized-operations-in-numpy/\n",
    "\n",
    "    loss =-np.mean(y_true*(np.log10(y_pred+1e-9)) + (1-y_true)*np.log10(1-y_pred+1e-9))   #to avoid division by zero error add 1e-9:reference taken from- #https://developer.ibm.com/articles/implementing-logistic-regression-from-scratch-in-python/\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = x*(y-sigmoid(np.dot(w.T,x)+b))+((alpha/N)*w)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    "def gradient_db(x,y,w,b):\n",
    "     '''In this function, we will compute gradient w.r.to b '''\n",
    "     db = y-sigmoid(np.dot(w,x)+b)   \n",
    "     return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function used to compute predicted_y given the dataset X\n",
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        predict.append(sigmoid(z))\n",
    "    return np.array(predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "     \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    w,b = initialize_weights(X_train[0]) # Initialize the weights\n",
    "    #code to perform SGD\n",
    "    for i in range(epochs):                           # for every epoch\n",
    "        for idx,x in enumerate(X_train) :             # for every data point(X_train,y_train)\n",
    "            dw=gradient_dw(x,y_train[idx],w,b,alpha,len(X_train))  #computing gradient w.r.to w \n",
    "            db=gradient_db(x,y_train[idx],w,b)        #computing gradient w.r.to b \n",
    "            w+=eta0*dw                                #update w  #Here eta0 is learning rate\n",
    "            b+=eta0*db                                #update b\n",
    "            \n",
    "        y_pred_tr=pred(w,b,X_train)           #preding y for the given x_train using logistic function\n",
    "        tr_loss=logloss(y_train,y_pred_tr)    #calculating log loss for train datapoints\n",
    "        train_loss.append(tr_loss)\n",
    "        \n",
    "        y_pred_te=pred(w,b,X_test)            #preding y for the given x_test using logistic function\n",
    "        te_loss=logloss(y_test,y_pred_te)     #calculating log loss for test datapoints\n",
    "        test_loss.append(te_loss)\n",
    "        if i>2:\n",
    "            if train_loss[-1]-train_loss[-2] <= 1e-3:     #if the first 3 decimal places of train loss does not change for the consequent epoch,stop the training process since data is fitted to model very well\n",
    "                break\n",
    "\n",
    "    return w,b,train_loss,test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "id": "sUquz7LFEZ6E"
   },
   "outputs": [],
   "source": [
    "alpha=0.001\n",
    "eta0=0.001\n",
    "N=len(X_train)\n",
    "epochs=20\n",
    "w,b,train_loss,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41395135  0.19245248 -0.1500517   0.32635332 -0.22516469  0.58646629\n",
      " -0.42720474 -0.10028062  0.2148384   0.15555088  0.17880941 -0.01318672\n",
      " -0.0649683   0.36313892 -0.00985027]\n",
      "-0.9016634051738529\n"
     ]
    }
   ],
   "source": [
    "#print the value of weights w and bias b\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00941556,  0.00697683, -0.00146134, -0.01509075, -0.01697799,\n",
       "          0.02630051,  0.02522009, -0.00619249,  0.0055652 , -0.02529038,\n",
       "         -0.0182425 , -0.01740588,  0.0146354 ,  0.0246109 , -0.03251748]]),\n",
       " array([-0.04852511]))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "## <font color='red'>Goal of this project</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in order of 10^-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Grader function - 1  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The custom weights are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this grader function should return True\n",
    "#the difference between custom weights and clf.coef_ should be less than or equal to 0.05\n",
    "def differece_check_grader(w,b,coef,intercept):\n",
    "    val_array=np.abs(np.array(w-coef))\n",
    "    assert(np.all(val_array<=0.05))\n",
    "    print('The custom weights are correct')\n",
    "    return True\n",
    "differece_check_grader(w,b,clf.coef_,clf.intercept_)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot train and test loss vs epochs </font>\n",
    "\n",
    "plot epoch number on X-axis and loss on Y-axis and make sure that the curve is converging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "id": "1O6GrRt7UeCJ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reference taken from :https://www.oreilly.com/library/view/machine-learning-with/9781787121515/cf4693e9-207a-4f74-826c-8190c3c8de97.xhtml\n",
    "from matplotlib import pyplot as plt \n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(test_loss,'r',linewidth=1.0)\n",
    "plt.plot(train_loss,'b',linewidth=1.0)\n",
    "plt.legend(['Training loss', 'test Loss'],fontsize=9)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUN8puFoEZtU"
   },
   "source": [
    "the data is well fitted with the model in few epochs itself.we get the **train log loss** of **0.1650592828382934** and **test log loss** of  **0.16614668451454206**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
